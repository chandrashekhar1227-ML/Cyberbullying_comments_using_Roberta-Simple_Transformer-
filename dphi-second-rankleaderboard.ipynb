{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install --upgrade transformers\n!pip install simpletransformers\n# memory footprint support libraries/code\n!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n!pip install gputil\n!pip install psutil\n!pip install humanize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import psutil\nimport humanize\nimport os\nimport GPUtil as GPU\n\nGPUs = GPU.getGPUs()\ngpu = GPUs[0]\ndef printm():\n    process = psutil.Process(os.getpid())\n    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\nprintm()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport warnings\nwarnings.simplefilter('ignore')\nimport gc\nfrom scipy.special import softmax\nfrom simpletransformers.classification import ClassificationModel\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold\nimport sklearn\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\nimport re\nimport random\nimport torch\npd.options.display.max_colwidth = 200\n\ndef seed_all(seed_value):\n    random.seed(seed_value) # Python\n    np.random.seed(seed_value) # cpu vars\n    torch.manual_seed(seed_value) # cpu  vars\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value) # gpu vars\n        torch.backends.cudnn.deterministic = True  #needed\n        torch.backends.cudnn.benchmark = False\n\nseed_all(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/cyberbullying_data/Training_set_label.csv\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/cyberbullying_data/Testing_set_label.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1=train.drop(['id'],axis=1)\ntest1=test.drop(['id'],axis=1)\ntest1['oh_label']=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nerr=[]\ny_pred_tot=[]\n\nfold=StratifiedKFold(n_splits=3, shuffle=True, random_state=2)\ni=1\nfor train_index, test_index in fold.split(train1,train1['oh_label']):\n    train1_trn, train1_val = train1.iloc[train_index], train1.iloc[test_index]\n    model = ClassificationModel('roberta', 'roberta-large', use_cuda=True,num_labels=2, args={'train_batch_size':32,\n                                                                         'reprocess_input_data': True,\n                                                                         'overwrite_output_dir': True,\n                                                                         'fp16': False,\n                                                                         'do_lower_case': False,\n                                                                         'num_train_epochs': 2,\n                                                                         'max_seq_length': 80,\n                                                                         'regression': False,\n                                                                         'manual_seed': 2,\n                                                                         \"learning_rate\":3e-5,\n                                                                         'weight_decay':0,\n                                                                         \"save_eval_checkpoints\": False,\n                                                                         \"save_model_every_epoch\": False,\n                                                                         \"silent\": True})\n    model.train_model(train1_trn)\n    raw_outputs_val = model.eval_model(train1_val)[1]\n    raw_outputs_val = softmax(raw_outputs_val,axis=1)[:,1]\n    print(f\"Log_Loss: {log_loss(train1_val['oh_label'], raw_outputs_val)}\")\n    err.append(log_loss(train1_val['oh_label'], raw_outputs_val))\n    raw_outputs_test = model.eval_model(test1)[1]\n    raw_outputs_test = softmax(raw_outputs_test,axis=1)[:,1]\n    y_pred_tot.append(raw_outputs_test)\nprint(\"Mean LogLoss: \",np.mean(err))\nfinal=pd.DataFrame()\n#final['ID']=test['ID']\nfinal['prediction']=np.mean(y_pred_tot, 0)\nprint(final.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.prediction.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.oh_label.value_counts()/len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final['prediction1']=final['prediction']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(final)):\n    if(final['prediction'][i]>=0.38):\n        final['prediction1'][i]=1\n    else:\n        final['prediction1'][i]=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss=pd.DataFrame(final['prediction1'].values,columns=['prediction'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final['prediction']=final['prediction'].round(decimals=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss['prediction'] =ss['prediction'].apply(np.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.to_csv('/kaggle/working/dphirobert15.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}